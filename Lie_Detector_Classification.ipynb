{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lie Detector Classification (LIAR dataset)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    classification_report,\n",
        ")\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "RANDOM_STATE = 42\n",
        "DATA_DIR = Path(\"data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded shapes and columns:\n",
            "train (10240, 14) ['id', 'label', 'statement', 'subject', 'speaker', 'job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context']\n",
            "valid (1284, 14) ['id', 'label', 'statement', 'subject', 'speaker', 'job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context']\n",
            "test (1267, 14) ['id', 'label', 'statement', 'subject', 'speaker', 'job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>statement</th>\n",
              "      <th>subject</th>\n",
              "      <th>speaker</th>\n",
              "      <th>job_title</th>\n",
              "      <th>state_info</th>\n",
              "      <th>party_affiliation</th>\n",
              "      <th>barely_true_counts</th>\n",
              "      <th>false_counts</th>\n",
              "      <th>half_true_counts</th>\n",
              "      <th>mostly_true_counts</th>\n",
              "      <th>pants_on_fire_counts</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2635.json</td>\n",
              "      <td>false</td>\n",
              "      <td>Says the Annies List political group supports ...</td>\n",
              "      <td>abortion</td>\n",
              "      <td>dwayne-bohac</td>\n",
              "      <td>State representative</td>\n",
              "      <td>Texas</td>\n",
              "      <td>republican</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>a mailer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10540.json</td>\n",
              "      <td>half-true</td>\n",
              "      <td>When did the decline of coal start? It started...</td>\n",
              "      <td>energy,history,job-accomplishments</td>\n",
              "      <td>scott-surovell</td>\n",
              "      <td>State delegate</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>democrat</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>a floor speech.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>324.json</td>\n",
              "      <td>mostly-true</td>\n",
              "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
              "      <td>foreign-policy</td>\n",
              "      <td>barack-obama</td>\n",
              "      <td>President</td>\n",
              "      <td>Illinois</td>\n",
              "      <td>democrat</td>\n",
              "      <td>70.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Denver</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1123.json</td>\n",
              "      <td>false</td>\n",
              "      <td>Health care reform legislation is likely to ma...</td>\n",
              "      <td>health-care</td>\n",
              "      <td>blog-posting</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>none</td>\n",
              "      <td>7.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>a news release</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9028.json</td>\n",
              "      <td>half-true</td>\n",
              "      <td>The economic turnaround started at the end of ...</td>\n",
              "      <td>economy,jobs</td>\n",
              "      <td>charlie-crist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Florida</td>\n",
              "      <td>democrat</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>an interview on CNN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id        label                                          statement  \\\n",
              "0   2635.json        false  Says the Annies List political group supports ...   \n",
              "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
              "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
              "3   1123.json        false  Health care reform legislation is likely to ma...   \n",
              "4   9028.json    half-true  The economic turnaround started at the end of ...   \n",
              "\n",
              "                              subject         speaker             job_title  \\\n",
              "0                            abortion    dwayne-bohac  State representative   \n",
              "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
              "2                      foreign-policy    barack-obama             President   \n",
              "3                         health-care    blog-posting                   NaN   \n",
              "4                        economy,jobs   charlie-crist                   NaN   \n",
              "\n",
              "  state_info party_affiliation  barely_true_counts  false_counts  \\\n",
              "0      Texas        republican                 0.0           1.0   \n",
              "1   Virginia          democrat                 0.0           0.0   \n",
              "2   Illinois          democrat                70.0          71.0   \n",
              "3        NaN              none                 7.0          19.0   \n",
              "4    Florida          democrat                15.0           9.0   \n",
              "\n",
              "   half_true_counts  mostly_true_counts  pants_on_fire_counts  \\\n",
              "0               0.0                 0.0                   0.0   \n",
              "1               1.0                 1.0                   0.0   \n",
              "2             160.0               163.0                   9.0   \n",
              "3               3.0                 5.0                  44.0   \n",
              "4              20.0                19.0                   2.0   \n",
              "\n",
              "               context  \n",
              "0             a mailer  \n",
              "1      a floor speech.  \n",
              "2               Denver  \n",
              "3       a news release  \n",
              "4  an interview on CNN  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1. Load the pre-split TSV files\n",
        "train_path = DATA_DIR / \"train.tsv\"\n",
        "valid_path = DATA_DIR / \"valid.tsv\"\n",
        "test_path = DATA_DIR / \"test.tsv\"\n",
        "\n",
        "# LIAR dataset official columns (files have no header row)\n",
        "liar_cols = [\n",
        "    \"id\",\n",
        "    \"label\",\n",
        "    \"statement\",\n",
        "    \"subject\",\n",
        "    \"speaker\",\n",
        "    \"job_title\",\n",
        "    \"state_info\",\n",
        "    \"party_affiliation\",\n",
        "    \"barely_true_counts\",\n",
        "    \"false_counts\",\n",
        "    \"half_true_counts\",\n",
        "    \"mostly_true_counts\",\n",
        "    \"pants_on_fire_counts\",\n",
        "    \"context\",\n",
        "]\n",
        "\n",
        "train_df = pd.read_csv(train_path, sep=\"\\t\", header=None, names=liar_cols)\n",
        "valid_df = pd.read_csv(valid_path, sep=\"\\t\", header=None, names=liar_cols)\n",
        "test_df = pd.read_csv(test_path, sep=\"\\t\", header=None, names=liar_cols)\n",
        "\n",
        "print(\"Loaded shapes and columns:\")\n",
        "for name, df in [(\"train\", train_df), (\"valid\", valid_df), (\"test\", test_df)]:\n",
        "    print(name, df.shape, list(df.columns))\n",
        "\n",
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After cleaning:\n",
            "train (10229, 15) {'truth': 0.5619317626356437, 'lie': 0.43806823736435624}\n",
            "valid (1284, 15) {'truth': 0.5202492211838006, 'lie': 0.4797507788161994}\n",
            "test (1267, 15) {'truth': 0.56353591160221, 'lie': 0.43646408839779005}\n"
          ]
        }
      ],
      "source": [
        "# 2. Clean data and map labels to binary (Lie=1, Truth=0)\n",
        "label_map = {\n",
        "    \"pants-fire\": 1,\n",
        "    \"false\": 1,\n",
        "    \"barely-true\": 1,\n",
        "    \"half-true\": 0,\n",
        "    \"mostly-true\": 0,\n",
        "    \"true\": 0,\n",
        "}\n",
        "\n",
        "def clean_and_map(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    # Remove rows with missing text or labels\n",
        "    df = df.dropna(subset=[\"statement\", \"label\"])\n",
        "    # Drop exact duplicates based on text + label\n",
        "    df = df.drop_duplicates(subset=[\"statement\", \"label\"])\n",
        "    # Map labels; rows with unmapped labels are removed\n",
        "    df[\"target\"] = df[\"label\"].map(label_map)\n",
        "    df = df.dropna(subset=[\"target\"])\n",
        "    df[\"target\"] = df[\"target\"].astype(int)\n",
        "    return df\n",
        "\n",
        "train_df = clean_and_map(train_df)\n",
        "valid_df = clean_and_map(valid_df)\n",
        "test_df = clean_and_map(test_df)\n",
        "\n",
        "print(\"After cleaning:\")\n",
        "for name, df in [(\"train\", train_df), (\"valid\", valid_df), (\"test\", test_df)]:\n",
        "    counts = df[\"target\"].value_counts(normalize=True).rename({0: \"truth\", 1: \"lie\"})\n",
        "    print(name, df.shape, counts.to_dict())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, y_train = train_df[\"statement\"], train_df[\"target\"]\n",
        "X_valid, y_valid = valid_df[\"statement\"], valid_df[\"target\"]\n",
        "X_test, y_test = test_df[\"statement\"], test_df[\"target\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Define pipelines and hyperparameter grids for classical ML models\n",
        "base_tfidf_params = {\n",
        "    \"tfidf__max_features\": [5000],\n",
        "    \"tfidf__ngram_range\": [(1, 2)],\n",
        "    \"tfidf__stop_words\": [\"english\"],\n",
        "    \"tfidf__min_df\": [2],\n",
        "}\n",
        "\n",
        "models_and_grids = {\n",
        "    \"Logistic Regression\": (\n",
        "        Pipeline([\n",
        "            (\"tfidf\", TfidfVectorizer()),\n",
        "            (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=RANDOM_STATE)),\n",
        "        ]),\n",
        "        {\n",
        "            **base_tfidf_params,\n",
        "            \"clf__C\": [0.5, 1.0, 2.0],\n",
        "            \"clf__penalty\": [\"l2\"],\n",
        "        },\n",
        "    ),\n",
        "    \"Linear SVM\": (\n",
        "        Pipeline([\n",
        "            (\"tfidf\", TfidfVectorizer()),\n",
        "            (\"clf\", LinearSVC(class_weight=\"balanced\", random_state=RANDOM_STATE)),\n",
        "        ]),\n",
        "        {\n",
        "            **base_tfidf_params,\n",
        "            \"clf__C\": [0.5, 1.0, 2.0],\n",
        "        },\n",
        "    ),\n",
        "    \"Naive Bayes\": (\n",
        "        Pipeline([\n",
        "            (\"tfidf\", TfidfVectorizer()),\n",
        "            (\"clf\", ComplementNB()),\n",
        "        ]),\n",
        "        {\n",
        "            **base_tfidf_params,\n",
        "            \"clf__alpha\": [0.5, 1.0, 2.0],\n",
        "        },\n",
        "    ),\n",
        "    \"KNN\": (\n",
        "        Pipeline([\n",
        "            (\"tfidf\", TfidfVectorizer()),\n",
        "            (\"clf\", KNeighborsClassifier()),\n",
        "        ]),\n",
        "        {\n",
        "            **base_tfidf_params,\n",
        "            \"clf__n_neighbors\": [3, 5, 7],\n",
        "            \"clf__weights\": [\"uniform\", \"distance\"],\n",
        "        },\n",
        "    ),\n",
        "    \"Decision Tree\": (\n",
        "        Pipeline([\n",
        "            (\"tfidf\", TfidfVectorizer()),\n",
        "            (\"clf\", DecisionTreeClassifier(random_state=RANDOM_STATE)),\n",
        "        ]),\n",
        "        {\n",
        "            **base_tfidf_params,\n",
        "            \"clf__max_depth\": [10, 30, None],\n",
        "            \"clf__min_samples_split\": [2, 5],\n",
        "        },\n",
        "    ),\n",
        "    \"Random Forest\": (\n",
        "        Pipeline([\n",
        "            (\"tfidf\", TfidfVectorizer()),\n",
        "            (\"clf\", RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1, class_weight=\"balanced\")),\n",
        "        ]),\n",
        "        {\n",
        "            **base_tfidf_params,\n",
        "            \"clf__n_estimators\": [100, 200],\n",
        "            \"clf__max_depth\": [None, 30],\n",
        "        },\n",
        "    ),\n",
        "    \"Gradient Boosting\": (\n",
        "        Pipeline([\n",
        "            (\"tfidf\", TfidfVectorizer()),\n",
        "            (\"clf\", GradientBoostingClassifier(random_state=RANDOM_STATE)),\n",
        "        ]),\n",
        "        {\n",
        "            **base_tfidf_params,\n",
        "            \"clf__n_estimators\": [100, 200],\n",
        "            \"clf__learning_rate\": [0.05, 0.1],\n",
        "        },\n",
        "    ),\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "\n",
        "def compute_prob_scores(model, X):\n",
        "    \"\"\"Return probability scores for ROC-AUC; fallback to decision function.\"\"\"\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        return model.predict_proba(X)[:, 1]\n",
        "    if hasattr(model, \"decision_function\"):\n",
        "        return model.decision_function(X)\n",
        "    # Fallback: use predictions \n",
        "    return model.predict(X)\n",
        "\n",
        "\n",
        "def evaluate_model(name, pipeline, param_grid):\n",
        "    grid = GridSearchCV(\n",
        "        pipeline,\n",
        "        param_grid=param_grid,\n",
        "        cv=cv,\n",
        "        scoring=\"f1\",\n",
        "        n_jobs=-1,\n",
        "        verbose=0,\n",
        "    )\n",
        "    grid.fit(X_train, y_train)\n",
        "    best_model = grid.best_estimator_\n",
        "    y_pred = best_model.predict(X_valid)\n",
        "    y_scores = compute_prob_scores(best_model, X_valid)\n",
        "\n",
        "    metrics = {\n",
        "        \"model\": name,\n",
        "        \"best_params\": grid.best_params_,\n",
        "        \"valid_accuracy\": accuracy_score(y_valid, y_pred),\n",
        "        \"valid_precision\": precision_score(y_valid, y_pred),\n",
        "        \"valid_recall\": recall_score(y_valid, y_pred),\n",
        "        \"valid_f1\": f1_score(y_valid, y_pred),\n",
        "    }\n",
        "    try:\n",
        "        metrics[\"valid_roc_auc\"] = roc_auc_score(y_valid, y_scores)\n",
        "    except Exception:\n",
        "        metrics[\"valid_roc_auc\"] = np.nan\n",
        "\n",
        "    print(f\"\\n{name} best params: {grid.best_params_}\")\n",
        "    print(classification_report(y_valid, y_pred, target_names=[\"Truth\", \"Lie\"]))\n",
        "    return best_model, metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\PC\\Documents\\school\\ML assignment\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Logistic Regression best params: {'clf__C': 0.5, 'clf__penalty': 'l2', 'tfidf__max_features': 5000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Truth       0.62      0.59      0.61       668\n",
            "         Lie       0.58      0.61      0.60       616\n",
            "\n",
            "    accuracy                           0.60      1284\n",
            "   macro avg       0.60      0.60      0.60      1284\n",
            "weighted avg       0.60      0.60      0.60      1284\n",
            "\n",
            "\n",
            "Linear SVM best params: {'clf__C': 0.5, 'tfidf__max_features': 5000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Truth       0.60      0.57      0.58       668\n",
            "         Lie       0.56      0.59      0.57       616\n",
            "\n",
            "    accuracy                           0.58      1284\n",
            "   macro avg       0.58      0.58      0.58      1284\n",
            "weighted avg       0.58      0.58      0.58      1284\n",
            "\n",
            "\n",
            "Naive Bayes best params: {'clf__alpha': 0.5, 'tfidf__max_features': 5000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Truth       0.62      0.61      0.62       668\n",
            "         Lie       0.58      0.59      0.59       616\n",
            "\n",
            "    accuracy                           0.60      1284\n",
            "   macro avg       0.60      0.60      0.60      1284\n",
            "weighted avg       0.60      0.60      0.60      1284\n",
            "\n",
            "\n",
            "KNN best params: {'clf__n_neighbors': 7, 'clf__weights': 'distance', 'tfidf__max_features': 5000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Truth       0.55      0.78      0.65       668\n",
            "         Lie       0.57      0.31      0.41       616\n",
            "\n",
            "    accuracy                           0.56      1284\n",
            "   macro avg       0.56      0.55      0.53      1284\n",
            "weighted avg       0.56      0.56      0.53      1284\n",
            "\n",
            "\n",
            "Decision Tree best params: {'clf__max_depth': None, 'clf__min_samples_split': 5, 'tfidf__max_features': 5000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Truth       0.57      0.61      0.59       668\n",
            "         Lie       0.54      0.51      0.52       616\n",
            "\n",
            "    accuracy                           0.56      1284\n",
            "   macro avg       0.56      0.56      0.56      1284\n",
            "weighted avg       0.56      0.56      0.56      1284\n",
            "\n",
            "\n",
            "Random Forest best params: {'clf__max_depth': 30, 'clf__n_estimators': 200, 'tfidf__max_features': 5000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Truth       0.64      0.63      0.64       668\n",
            "         Lie       0.61      0.62      0.61       616\n",
            "\n",
            "    accuracy                           0.63      1284\n",
            "   macro avg       0.62      0.63      0.63      1284\n",
            "weighted avg       0.63      0.63      0.63      1284\n",
            "\n",
            "\n",
            "Gradient Boosting best params: {'clf__learning_rate': 0.1, 'clf__n_estimators': 200, 'tfidf__max_features': 5000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': 'english'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Truth       0.57      0.88      0.69       668\n",
            "         Lie       0.69      0.29      0.41       616\n",
            "\n",
            "    accuracy                           0.60      1284\n",
            "   macro avg       0.63      0.58      0.55      1284\n",
            "weighted avg       0.63      0.60      0.55      1284\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>best_params</th>\n",
              "      <th>valid_accuracy</th>\n",
              "      <th>valid_precision</th>\n",
              "      <th>valid_recall</th>\n",
              "      <th>valid_f1</th>\n",
              "      <th>valid_roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>{'clf__max_depth': 30, 'clf__n_estimators': 20...</td>\n",
              "      <td>0.625389</td>\n",
              "      <td>0.607656</td>\n",
              "      <td>0.618506</td>\n",
              "      <td>0.613033</td>\n",
              "      <td>0.669928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>{'clf__C': 0.5, 'clf__penalty': 'l2', 'tfidf__...</td>\n",
              "      <td>0.602804</td>\n",
              "      <td>0.581538</td>\n",
              "      <td>0.613636</td>\n",
              "      <td>0.597156</td>\n",
              "      <td>0.655907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>{'clf__alpha': 0.5, 'tfidf__max_features': 500...</td>\n",
              "      <td>0.601246</td>\n",
              "      <td>0.583601</td>\n",
              "      <td>0.589286</td>\n",
              "      <td>0.586430</td>\n",
              "      <td>0.645406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Linear SVM</td>\n",
              "      <td>{'clf__C': 0.5, 'tfidf__max_features': 5000, '...</td>\n",
              "      <td>0.577103</td>\n",
              "      <td>0.556068</td>\n",
              "      <td>0.587662</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.620694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>{'clf__max_depth': None, 'clf__min_samples_spl...</td>\n",
              "      <td>0.558411</td>\n",
              "      <td>0.542609</td>\n",
              "      <td>0.506494</td>\n",
              "      <td>0.523929</td>\n",
              "      <td>0.562645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNN</td>\n",
              "      <td>{'clf__n_neighbors': 7, 'clf__weights': 'dista...</td>\n",
              "      <td>0.558411</td>\n",
              "      <td>0.572700</td>\n",
              "      <td>0.313312</td>\n",
              "      <td>0.405037</td>\n",
              "      <td>0.582294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>{'clf__learning_rate': 0.1, 'clf__n_estimators...</td>\n",
              "      <td>0.595016</td>\n",
              "      <td>0.686047</td>\n",
              "      <td>0.287338</td>\n",
              "      <td>0.405034</td>\n",
              "      <td>0.652465</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 model                                        best_params  \\\n",
              "0        Random Forest  {'clf__max_depth': 30, 'clf__n_estimators': 20...   \n",
              "1  Logistic Regression  {'clf__C': 0.5, 'clf__penalty': 'l2', 'tfidf__...   \n",
              "2          Naive Bayes  {'clf__alpha': 0.5, 'tfidf__max_features': 500...   \n",
              "3           Linear SVM  {'clf__C': 0.5, 'tfidf__max_features': 5000, '...   \n",
              "4        Decision Tree  {'clf__max_depth': None, 'clf__min_samples_spl...   \n",
              "5                  KNN  {'clf__n_neighbors': 7, 'clf__weights': 'dista...   \n",
              "6    Gradient Boosting  {'clf__learning_rate': 0.1, 'clf__n_estimators...   \n",
              "\n",
              "   valid_accuracy  valid_precision  valid_recall  valid_f1  valid_roc_auc  \n",
              "0        0.625389         0.607656      0.618506  0.613033       0.669928  \n",
              "1        0.602804         0.581538      0.613636  0.597156       0.655907  \n",
              "2        0.601246         0.583601      0.589286  0.586430       0.645406  \n",
              "3        0.577103         0.556068      0.587662  0.571429       0.620694  \n",
              "4        0.558411         0.542609      0.506494  0.523929       0.562645  \n",
              "5        0.558411         0.572700      0.313312  0.405037       0.582294  \n",
              "6        0.595016         0.686047      0.287338  0.405034       0.652465  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 4. Train, tune, and evaluate on validation set\n",
        "model_results = []\n",
        "best_models = {}\n",
        "\n",
        "for name, (pipeline, grid) in models_and_grids.items():\n",
        "    best_model, metrics = evaluate_model(name, pipeline, grid)\n",
        "    model_results.append(metrics)\n",
        "    best_models[name] = best_model\n",
        "\n",
        "results_df = pd.DataFrame(model_results)\n",
        "results_df = results_df.sort_values(by=\"valid_f1\", ascending=False).reset_index(drop=True)\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected best model: Random Forest\n",
            "\n",
            "Test classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Truth       0.66      0.63      0.64       714\n",
            "         Lie       0.55      0.58      0.56       553\n",
            "\n",
            "    accuracy                           0.61      1267\n",
            "   macro avg       0.60      0.60      0.60      1267\n",
            "weighted avg       0.61      0.61      0.61      1267\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'test_accuracy': 0.6077348066298343,\n",
              " 'test_precision': 0.5477815699658704,\n",
              " 'test_recall': 0.5804701627486437,\n",
              " 'test_f1': 0.5636523266022827,\n",
              " 'test_roc_auc': 0.6401851879992504}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 5. Pick best model by validation F1 and evaluate on test set\n",
        "best_row = results_df.iloc[0]\n",
        "best_name = best_row[\"model\"]\n",
        "best_model = best_models[best_name]\n",
        "\n",
        "print(f\"Selected best model: {best_name}\")\n",
        "\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "y_test_scores = compute_prob_scores(best_model, X_test)\n",
        "\n",
        "test_metrics = {\n",
        "    \"test_accuracy\": accuracy_score(y_test, y_test_pred),\n",
        "    \"test_precision\": precision_score(y_test, y_test_pred),\n",
        "    \"test_recall\": recall_score(y_test, y_test_pred),\n",
        "    \"test_f1\": f1_score(y_test, y_test_pred),\n",
        "}\n",
        "try:\n",
        "    test_metrics[\"test_roc_auc\"] = roc_auc_score(y_test, y_test_scores)\n",
        "except Exception:\n",
        "    test_metrics[\"test_roc_auc\"] = np.nan\n",
        "\n",
        "print(\"\\nTest classification report:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=[\"Truth\", \"Lie\"]))\n",
        "\n",
        "test_metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved comparison table -> C:\\Users\\PC\\Documents\\school\\ML assignment\\model_comparison.csv\n",
            "Saved best model -> C:\\Users\\PC\\Documents\\school\\ML assignment\\best_model.pkl\n"
          ]
        }
      ],
      "source": [
        "# 6. Persist artifacts\n",
        "comparison_path = Path(\"model_comparison.csv\")\n",
        "best_model_path = Path(\"best_model.pkl\")\n",
        "\n",
        "results_df.to_csv(comparison_path, index=False)\n",
        "joblib.dump(best_model, best_model_path)\n",
        "\n",
        "print(f\"Saved comparison table -> {comparison_path.resolve()}\")\n",
        "print(f\"Saved best model -> {best_model_path.resolve()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notes\n",
        "- TF-IDF is fit only on the training split to avoid leakage.\n",
        "- All models use 3-fold Stratified CV with F1 scoring for tuning.\n",
        "- `model_comparison.csv` holds validation metrics; `best_model.pkl` stores the tuned pipeline ready for inference via `predict` or `predict_proba`.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
